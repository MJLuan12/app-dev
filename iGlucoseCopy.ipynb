{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEzDLFjvBLnmkmSHM2BJ6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJLuan12/app-dev/blob/main/iGlucoseCopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k0pwoMRWiR5E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
        "from skimage import exposure\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import deeplake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50  # Increase epochs for fine-tuning\n",
        "LEARNING_RATE = 0.0001\n",
        "CLASS_NAMES = ['0', '1', '2', '3', '4']  # Adjust based on DRD dataset labels"
      ],
      "metadata": {
        "id": "7GdIA9-di7sk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_image(image):\n",
        "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "    image = preprocess_input(image)  # Apply ResNet50's preprocessing\n",
        "    return image"
      ],
      "metadata": {
        "id": "pAoohs7vi_Em"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "def create_model():\n",
        "    # Load the ResNet50 model with pre-trained ImageNet weights\n",
        "    image_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "\n",
        "    # Initially freeze all layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add new layers on top of the ResNet50 output\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "    # Create the final model\n",
        "    model = Model(inputs=image_input, outputs=predictions)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ikWsqo7AjCXL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compilation (initial training)\n",
        "model = create_model()\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=LEARNING_RATE, weight_decay=0.01),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "-Bblu9KLjzFn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DRD datasets from Deep Lake\n",
        "train_ds = deeplake.load(\"hub://activeloop/diabetic-retinopathy-detection-train\")\n",
        "test_ds = deeplake.load(\"hub://activeloop/diabetic-retinopathy-detection-test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9aRYHdVkzv7",
        "outputId": "a4dd83ba-fab9-44e9-bbd3-ead569a9a2aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/diabetic-retinopathy-detection-train\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/diabetic-retinopathy-detection-train loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "-"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/diabetic-retinopathy-detection-test\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/diabetic-retinopathy-detection-test loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the training labels (assuming the label tensor is named 'diagnosis')\n",
        "train_labels = train_ds.labels.numpy()  # Convert to NumPy array\n",
        "train_labels = train_labels.flatten()  # Convert to a 1D array"
      ],
      "metadata": {
        "id": "xg1onR6akyQt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "CYTa67-cj24i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('diabetic_retinopathy_model_best_resnet.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "2TmlcYryj5Oq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    return lr * tf.math.exp(-0.1) if epoch >= 10 else lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "callbacks = [early_stopping, checkpoint, reduce_lr, lr_scheduler]"
      ],
      "metadata": {
        "id": "yG9vZ5Prj7n8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to prepare images\n",
        "def preprocess(image):\n",
        "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "    image = preprocess_input(image)  # Apply ResNet50's preprocessing\n",
        "    return image"
      ],
      "metadata": {
        "id": "YrFpSSgEj_9K"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow data loaders\n",
        "train_dataloader = train_ds.tensorflow(batch_size=BATCH_SIZE, shuffle=True).map(lambda x: (preprocess(x[0]), x[1]))\n",
        "test_dataloader = test_ds.tensorflow(batch_size=BATCH_SIZE, shuffle=False).map(lambda x: (preprocess(x[0]), x[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "qV-XigHtkCDo",
        "outputId": "06e7e4f2-5cc9-475f-97b5-6dd23ca37731"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Dataset.tensorflow() got an unexpected keyword argument 'batch_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-c040e9c2038b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create TensorFlow data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Dataset.tensorflow() got an unexpected keyword argument 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model (first stage: only train the new layers)\n",
        "history = model.fit(\n",
        "    train_dataloader,\n",
        "    epochs=10,  # Train for a few epochs to get the new layers warmed up\n",
        "    validation_data=test_dataloader, # Using test set for validation during initial training\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "8LQBOmNskDjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning: Unfreeze some ResNet50 layers\n",
        "for layer in base_model.layers[-20:]:  # Unfreeze the last 20 layers of ResNet50\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "aaVHLtO2kF1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-compile with a lower learning rate\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=LEARNING_RATE / 10, weight_decay=0.01),  # Adjust learning rate for fine-tuning\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "IKHbxHuekHVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "history = model.fit(\n",
        "    train_dataloader,\n",
        "    epochs=EPOCHS,  # Train for more epochs for fine-tuning\n",
        "    validation_data=test_dataloader,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "8cl-lgcmkJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation (using validation data loader)\n",
        "validation_images, validation_labels = next(iter(val_dl))  # Get a batch from the validation data loader\n",
        "predictions = model.predict(validation_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(validation_labels, axis=1)"
      ],
      "metadata": {
        "id": "oS_4A7o-kOh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "recall = recall_score(true_classes, predicted_classes, average='macro')\n",
        "precision = precision_score(true_classes, predicted_classes, average='macro')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='macro')\n",
        "mcc = matthews_corrcoef(true_classes, predicted_classes)\n",
        "auc_roc = roc_auc_score(validation_labels, predictions, multi_class='ovr')\n"
      ],
      "metadata": {
        "id": "jYXBAHcekPCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'Matthews Correlation Coefficient: {mcc}')\n",
        "print(f'AUC-ROC: {auc_roc}')"
      ],
      "metadata": {
        "id": "EjFEZlYRkRlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EtDhbtK_kTHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('diabetic_retinopathy_model_finetuned_resnet.h5')"
      ],
      "metadata": {
        "id": "IKymQIaPkUwX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}